import re
from unicodedata import normalize
import pandas as pd
import visen
from time import time

opening_ls = ['[', '{', 'â…', 'âŒ©', 'â¡', 'â¢', 'â£', 'â§', 'â¨', 'â©', 'â¬', 'â°', 'â²', 'â´', 'âŸ¦', 'âŸ¨', 'âŸª', 'âŸ¬', 'â¦ƒ', 'â¦‡', 'â¦‰',
              'â¦‹', 'â¦', 'â¦', 'â¦‘', 'â¦“', 'â¦•', 'â¦—', 'â§¼', 'â¸‚', 'â¸„', 'â¸‰', 'â¸Œ', 'â¸œ', 'â¸¢', 'â¸¤', 'â¸¦', 'ã€ˆ', 'ã€Š', 'ã€Œ', 'ã€',
              'ã€', 'ã€”', 'ã€–', 'ã€˜', 'ã€š', 'ï¹›', 'ï¹', 'ï¼»', 'ï½›', 'ï½¢', 'ï½£']

closing_ls = [']', '}', 'â†', 'âŒª', 'â¤', 'â¥', 'â¦', 'â«', 'â¬', 'â­', 'â­', 'â±', 'â³', 'âµ', 'âŸ§', 'âŸ©', 'âŸ«', 'âŸ­', 'â¦„', 'â¦ˆ', 'â¦Š',
              'â¦Œ', 'â¦', 'â¦', 'â¦’', 'â¦”', 'â¦–', 'â¦˜', 'â§½', 'â¸ƒ', 'â¸…', 'â¸Š', 'â¸', 'â¸', 'â¸£', 'â¸¥', 'â¸§', 'ã€‰', 'ã€‹', 'ã€', 'ã€',
              'ã€‘', 'ã€•', 'ã€—', 'ã€™', 'ã€›', 'ï¹œ', 'ï¹', 'ï¼½', 'ï½', 'ï½£']

opening_bracket = {key: '(' for key in opening_ls}
closing_bracket = {key: ')' for key in closing_ls}

opening_bracket_pattern = {f"\\{key}": "(" for key in opening_ls}
closing_bracket_pattern = {f"\\{key}": ")" for key in closing_ls}

PUNC = '!\"#$&()*+,-â€“âˆ’./:;=?@[\]^_`{|}~â€â€œ`Â°Â²Ëˆâ€ã„§â€›âˆ¼â€™'  # remove <> for number_sym and unknown_sym
re_num_and_decimal = '[0-9]*[,.\-]*[0-9]*[,.\-]*[0-9]*[.,\-]*[0-9]*[,.\-]*[0-9]+[.,]?'
re_unknown = '[a-z]+[\d]+[\w]*|[\d]+[a-z]+[\w]*'
re_vnese_txt = r'[^a-z0-9A-ZÃ Ã¡Ã£áº¡áº£Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº¹áº»áº½Ãªá»áº¿á»ƒá»…á»‡Ä‘Ã¬Ã­Ä©á»‰á»‹Ã²Ã³Ãµá»á»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹ÃºÅ©á»¥á»§Æ°á»©á»«á»­á»¯á»±á»³á»µá»·á»¹Ã½Ã€ÃÃƒáº áº¢Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬ÃˆÃ‰' \
               r'áº¸áººáº¼ÃŠá»€áº¾á»‚á»„á»†ÄÃŒÃÄ¨á»ˆá»ŠÃ’Ã“Ã•á»Œá»Ã”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢Ã™ÃšÅ¨á»¤á»¦Æ¯á»¨á»ªá»¬á»®á»°á»²á»´á»¶á»¸Ã\s|_]'
special_punc = {'â€': '"', '': '', "â€™": "'", "`": "'"}


def replace_all(replacer: dict, txt: str) -> str:
    """
    Replace all the keys in the dictionary with their respective values.
    :param replacer: dictionary of keys are the words to be replaced and values are the words to replace them with
    :param txt: subject string
    :return: string after replacement
    """
    for old, new in replacer.items():
        txt = txt.replace(old, new)
    return txt


def replace_num(txt: str) -> str:
    """
    Replace all the numbers in the text with blank
    :param text: subject string
    :return: string after replacement
    """
    text = re.sub(re_num_and_decimal, '', txt)
    return text


def replace_unknown(text: str) -> str:
    """
    Replace all the predefined unknown symbols in the text with blank
    :param text: subject string
    :return: string after replacement
    """
    text = re.sub(re_unknown, '', text)
    return text


def unicode_normalizer(text, forms: list = ['NFKC', 'NKFD', 'NFC', 'NFD']) -> str:
    """
    Normalize unicode text
    :param text: subject string
    :param forms: unicode normalization forms
    :return: string after normalization
    """
    for form in forms:
        text = normalize(form, text)
    return text


def normalize_bracket(text: str) -> str:
    """
    Normalize brackets in the text with predefined string for later use
    :param text: subject string
    :return: transformed string
    """
    text = replace_all(opening_bracket, text)
    text = replace_all(closing_bracket, text)
    text = re.sub(r"[\(\[].*?[\)\]]", "", text)
    return text


def remove_punc(text: str) -> str:
    """
    Remove punctuations in the text
    :param text: subject string
    :return: string after removal
    """
    r = re.compile(r'[\s{}]+'.format(re.escape(PUNC)))
    text = r.split(text)
    return ' '.join(i for i in text if i)


def norm(text: str) -> str:
    """
    Normalize text by removing punctuations, numbers, unknown symbols, brackets, and normalize unicode
    :param text: subject string
    :return: normalized string
    """
    text = str(text)
    text = text.lower()
    text = text.split('\n')[0]
    text = unicode_normalizer(text, ["NFKC", "NFKD", "NFD", "NFC"])
    text = replace_all(special_punc, text)
    text = normalize_bracket(text)
    text = replace_unknown(text)
    text = replace_num(text)
    text = remove_punc(text)
    text = re.sub(re_vnese_txt, "", text)
    text = text.strip()
    return visen.clean_tone(text)


def dataframe_normalize(df: pd.DataFrame = None) -> pd.DataFrame:
    """
    Normalize dataframe
    :param df: Dataframe to normalize
    :return: Dataframe normalized
    """
    assert 'sample' in df.columns, f"DataFrame with column name 'sample' expected, got {df.columns} "
    begin = time()

    df['sample'] = df['sample'].str.lower()
    df['sample'] = df['sample'].str.replace('[a-z]+[\d]+[\w]*|[\d]+[a-z]+[\w]*', '',
                                            regex=True)  # replace all product code with blank
    df['sample'] = df['sample'].str.replace('[0-9]*[,.\-]*[0-9]*[,.\-]*[0-9]*[.,\-]*[0-9]*[,.\-]*[0-9]+[.,]?', '',
                                            regex=True)  # replace all number with blank
    df['sample'] = df['sample'].replace(opening_bracket_pattern, regex=True)  # normalize opening brackets, listed above
    df['sample'] = df['sample'].replace(closing_bracket_pattern, regex=True)  # normalize closing brackets, listed above
    df['sample'] = df['sample'].str.replace("[\(\[].*?[\)\]]", '',
                                            regex=True)  # remove all content inside brackets, eg: (SiÃªu sale 12/12)
    df['sample'] = df['sample'].str.normalize('NFKC')  # Normalize unicode with NFKC standard
    df['sample'] = df['sample'].str.normalize('NFKD')
    df['sample'] = df['sample'].str.normalize('NFC')
    df['sample'] = df['sample'].str.normalize('NFD')
    #   # Remove non Vietnamese text, seems like unessesary right now, might consider remove later to improve run time.
    df['sample'] = df['sample'].str.replace(
        r"[^a-z0-9A-ZÃ Ã¡Ã£áº¡áº£Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã¨Ã©áº¹áº»áº½Ãªá»áº¿á»ƒá»…á»‡Ä‘Ã¬Ã­Ä©á»‰á»‹Ã²Ã³Ãµá»á»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£Ã¹ÃºÅ©á»¥á»§Æ°á»©á»«á»­á»¯á»±á»³á»µá»·á»¹Ã½Ã€ÃÃƒáº áº¢Ä‚áº®áº°áº²áº´áº¶Ã‚áº¤áº¦áº¨áºªáº¬ÃˆÃ‰áº¸áººáº¼ÃŠá»€áº¾á»‚á»„á»†ÄÃŒÃÄ¨á»ˆá»ŠÃ’Ã“Ã•á»Œá»Ã”á»á»’á»”á»–á»˜Æ á»šá»œá»á» á»¢Ã™ÃšÅ¨á»¤á»¦Æ¯á»¨á»ªá»¬á»®á»°á»²á»´á»¶á»¸Ã\s|_]",
        '', regex=True)
    df['sample'] = df['sample'].str.replace('Ä‘',
                                            'd').str.strip()  # Special case where unicode normalizer does not consider 'Ä‘' a combination of base unicode characters
    print('Total enlapsed time:', time() - begin, 'seconds')
    return df


if __name__ == '__main__':
    sample_txts = [
        'ã€–ğ”°ğ”¬ğ”ªğ”¢ ğ”£ğ”ğ”«ğ” ğ”¶ ğ”­ğ”¯ğ”¬ğ”¡ğ”²ğ” ğ”± ğ”«ğ”ğ”ªğ”¢ã€—',
        'ğ–˜ğ–”ğ–’ğ–Š ğ–‹ğ–†ğ–“ğ–ˆğ– ğ–•ğ–—ğ–”ğ–‰ğ–šğ–ˆğ–™ ğ–“ğ–†ğ–’ğ–Š',
        'â°some product code which will overfit this sampleâ± ğ“¼ğ“¸ğ“¶ğ“® ğ“¯ğ“ªğ“·ğ“¬ğ”‚ ğ“¹ğ“»ğ“¸ğ“­ğ“¾ğ“¬ğ“½ ğ“·ğ“ªğ“¶ğ“®',
        'ğ“ˆğ‘œğ“‚ğ‘’ ğ’»ğ’¶ğ“ƒğ’¸ğ“ ğ“…ğ“‡ğ‘œğ’¹ğ“Šğ’¸ğ“‰ ğ“ƒğ’¶ğ“‚ğ‘’',
        '{ğ•¤ğ• ğ•ğ•– ğ•—ğ•’ğ•Ÿğ•”ğ•ª ğ•¡ğ•£ğ• ğ••ğ•¦ğ•”ğ•¥ ğ•Ÿğ•’ğ•ğ•–',
        'â˜¯ğŸ˜ï½“ï½ï½ï½… ï½†ï½ï½ï½ƒï½™ ï½ï½’ï½ï½„ï½•ï½ƒï½” ï½ï½ï½ï½…â˜¯ğŸ˜',
        'ğ¬ğ¨ğ¦ğ ğŸğšğ§ğœğ² ğ©ğ«ğ¨ğğ®ğœğ­ ğ§ğšğ¦ğ',
        'ğ˜€ğ—¼ğ—ºğ—² ğ—³ğ—®ğ—»ğ—°ğ˜† ğ—½ğ—¿ğ—¼ğ—±ğ˜‚ğ—°ğ˜ ğ—»ğ—®ğ—ºğ—²',
        'ğ˜´ğ˜°ğ˜®ğ˜¦ ğ˜§ğ˜¢ğ˜¯ğ˜¤ğ˜º ğ˜±ğ˜³ğ˜°ğ˜¥ğ˜¶ğ˜¤ğ˜µ ğ˜¯ğ˜¢ğ˜®ğ˜¦',
        'â–„â–€â–„â–€â–„â–€ ğ™¨ğ™¤ğ™¢ğ™š ğ™›ğ™–ğ™£ğ™˜ğ™® ğ™¥ğ™§ğ™¤ğ™™ğ™ªğ™˜ğ™© ğ™£ğ™–ğ™¢ğ™š â–„â–€â–„â–€â–„â–€',
        'ğŸŒŒ  ğŸ€ ğšœğš˜ğš–ğš ğšğšŠğš—ğšŒğš¢ ğš™ğš›ğš˜ğšğšğšŒğš ğš—ğšŠğš–ğšğŸŒŒ  ğŸ€ ',
        '(ã£â—”â—¡â—”)ã£ â™¥ some fancy product name â™¥',
    ]

    for sample in sample_txts:
        print(f'sample \"{sample}\", after normalize: \"{norm(sample)}\"')
